#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
JSONLæ–‡ä»¶åˆ†å‰²è„šæœ¬
å°†å¤§å‹JSONLæ–‡ä»¶æŒ‰æŒ‡å®šè¡Œæ•°åˆ†å‰²æˆå¤šä¸ªå°æ–‡ä»¶

ä½¿ç”¨æ–¹æ³•:
    python split_jsonl.py input.jsonl                    # é»˜è®¤æ¯10ä¸‡è¡Œåˆ†å‰²ä¸€æ¬¡
    python split_jsonl.py input.jsonl -n 50000          # æ¯5ä¸‡è¡Œåˆ†å‰²ä¸€æ¬¡
    python split_jsonl.py input.jsonl -o output_dir     # æŒ‡å®šè¾“å‡ºç›®å½•
    python split_jsonl.py input.jsonl --validate        # åˆ†å‰²æ—¶éªŒè¯JSONæ ¼å¼
"""

import os
import json
import argparse
import sys
from pathlib import Path


def validate_json_line(line, line_num):
    """
    éªŒè¯ä¸€è¡Œæ˜¯å¦ä¸ºæœ‰æ•ˆçš„JSONæ ¼å¼
    
    Args:
        line (str): è¦éªŒè¯çš„è¡Œ
        line_num (int): è¡Œå·
        
    Returns:
        bool: æ˜¯å¦ä¸ºæœ‰æ•ˆJSON
    """
    try:
        json.loads(line.strip())
        return True
    except json.JSONDecodeError as e:
        print(f"   âš ï¸  ç¬¬{line_num}è¡ŒJSONæ ¼å¼é”™è¯¯: {str(e)[:50]}")
        return False


def get_output_filename(base_name, output_dir, part_num, total_parts=None):
    """
    ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    
    Args:
        base_name (str): åŸæ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
        output_dir (str): è¾“å‡ºç›®å½•
        part_num (int): åˆ†ç‰‡ç¼–å·
        total_parts (int): æ€»åˆ†ç‰‡æ•°ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        str: å®Œæ•´çš„è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    if total_parts and total_parts > 0:
        # å¦‚æœçŸ¥é“æ€»åˆ†ç‰‡æ•°ï¼Œä½¿ç”¨å›ºå®šå®½åº¦çš„ç¼–å·
        width = len(str(total_parts))
        filename = f"{base_name}_part_{part_num:0{width}d}.jsonl"
    else:
        # å¦åˆ™ä½¿ç”¨ç®€å•ç¼–å·
        filename = f"{base_name}_part_{part_num:04d}.jsonl"
    
    return os.path.join(output_dir, filename)


def estimate_total_lines(file_path, sample_size=1000):
    """
    ä¼°ç®—æ–‡ä»¶æ€»è¡Œæ•°ï¼ˆç”¨äºå¤§æ–‡ä»¶ï¼‰
    
    Args:
        file_path (str): æ–‡ä»¶è·¯å¾„
        sample_size (int): é‡‡æ ·è¡Œæ•°
        
    Returns:
        int: ä¼°ç®—çš„æ€»è¡Œæ•°
    """
    try:
        file_size = os.path.getsize(file_path)
        
        # å¯¹äºå°æ–‡ä»¶ï¼Œç›´æ¥è®¡ç®—
        if file_size < 100 * 1024 * 1024:  # å°äº100MB
            with open(file_path, 'r', encoding='utf-8') as f:
                return sum(1 for line in f if line.strip())
        
        # å¯¹äºå¤§æ–‡ä»¶ï¼Œé‡‡æ ·ä¼°ç®—
        with open(file_path, 'r', encoding='utf-8') as f:
            sample_lines = []
            for i, line in enumerate(f):
                if i >= sample_size:
                    break
                sample_lines.append(len(line.encode('utf-8')))
            
            if sample_lines:
                avg_line_size = sum(sample_lines) / len(sample_lines)
                estimated_lines = int(file_size / avg_line_size)
                return estimated_lines
            
        return 0
        
    except Exception as e:
        print(f"âš ï¸  æ— æ³•ä¼°ç®—æ–‡ä»¶è¡Œæ•°: {e}")
        return 0


def split_jsonl_file(input_file, output_dir, lines_per_file=100000, validate=False):
    """
    åˆ†å‰²JSONLæ–‡ä»¶
    
    Args:
        input_file (str): è¾“å…¥æ–‡ä»¶è·¯å¾„
        output_dir (str): è¾“å‡ºç›®å½•
        lines_per_file (int): æ¯ä¸ªæ–‡ä»¶çš„è¡Œæ•°
        validate (bool): æ˜¯å¦éªŒè¯JSONæ ¼å¼
        
    Returns:
        dict: åˆ†å‰²ç»“æœç»Ÿè®¡
    """
    input_path = Path(input_file)
    if not input_path.exists():
        raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # è·å–æ–‡ä»¶åŸºæœ¬ä¿¡æ¯
    base_name = input_path.stem
    file_size_mb = os.path.getsize(input_file) / (1024 * 1024)
    
    print(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {input_path.name}")
    print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ“¦ æ¯æ–‡ä»¶è¡Œæ•°: {lines_per_file:,}")
    
    # ä¼°ç®—æ€»è¡Œæ•°å’Œåˆ†ç‰‡æ•°
    if file_size_mb > 10:  # å¤§äº10MBæ‰ä¼°ç®—
        print("ğŸ” æ­£åœ¨ä¼°ç®—æ–‡ä»¶å¤§å°...")
        estimated_lines = estimate_total_lines(input_file)
        if estimated_lines > 0:
            estimated_parts = (estimated_lines + lines_per_file - 1) // lines_per_file
            print(f"ğŸ“ˆ ä¼°ç®—æ€»è¡Œæ•°: {estimated_lines:,}")
            print(f"ğŸ“¦ é¢„è®¡åˆ†ç‰‡æ•°: {estimated_parts}")
        else:
            estimated_parts = None
    else:
        estimated_parts = None
    
    print("=" * 60)
    
    # å¼€å§‹åˆ†å‰²
    stats = {
        'total_lines': 0,
        'valid_lines': 0,
        'invalid_lines': 0,
        'output_files': [],
        'empty_lines_skipped': 0
    }
    
    try:
        with open(input_file, 'r', encoding='utf-8') as infile:
            current_part = 1
            current_file = None
            current_file_lines = 0
            
            for line_num, line in enumerate(infile, 1):
                # è·³è¿‡ç©ºè¡Œ
                if not line.strip():
                    stats['empty_lines_skipped'] += 1
                    continue
                
                stats['total_lines'] += 1
                
                # éªŒè¯JSONæ ¼å¼ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if validate:
                    if validate_json_line(line, line_num):
                        stats['valid_lines'] += 1
                    else:
                        stats['invalid_lines'] += 1
                        continue  # è·³è¿‡æ— æ•ˆè¡Œ
                else:
                    stats['valid_lines'] += 1
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ›å»ºæ–°æ–‡ä»¶
                if current_file is None or current_file_lines >= lines_per_file:
                    # å…³é—­å½“å‰æ–‡ä»¶
                    if current_file is not None:
                        current_file.close()
                        print(f"âœ… å®Œæˆåˆ†ç‰‡ {current_part-1}: {current_file_lines:,} è¡Œ")
                    
                    # åˆ›å»ºæ–°æ–‡ä»¶
                    output_filename = get_output_filename(
                        base_name, output_dir, current_part, estimated_parts
                    )
                    current_file = open(output_filename, 'w', encoding='utf-8')
                    stats['output_files'].append(output_filename)
                    current_file_lines = 0
                    
                    print(f"ğŸ“ å¼€å§‹å†™å…¥åˆ†ç‰‡ {current_part}: {os.path.basename(output_filename)}")
                    current_part += 1
                
                # å†™å…¥è¡Œåˆ°å½“å‰æ–‡ä»¶
                current_file.write(line)
                current_file_lines += 1
                
                # æ˜¾ç¤ºè¿›åº¦
                if line_num % 10000 == 0:
                    print(f"   ğŸ“Š å·²å¤„ç† {line_num:,} è¡Œ (å½“å‰åˆ†ç‰‡: {current_file_lines:,} è¡Œ)")
            
            # å…³é—­æœ€åä¸€ä¸ªæ–‡ä»¶
            if current_file is not None:
                current_file.close()
                print(f"âœ… å®Œæˆåˆ†ç‰‡ {current_part-1}: {current_file_lines:,} è¡Œ")
                
    except UnicodeDecodeError:
        print("âŒ æ–‡ä»¶ç¼–ç é”™è¯¯ï¼Œå°è¯•ä½¿ç”¨GBKç¼–ç ...")
        try:
            # é‡æ–°å°è¯•ç”¨GBKç¼–ç å¤„ç†
            with open(input_file, 'r', encoding='gbk') as infile:
                # ... é‡å¤ä¸Šé¢çš„å¤„ç†é€»è¾‘
                pass
        except Exception as e:
            raise Exception(f"æ— æ³•è¯»å–æ–‡ä»¶: {e}")
            
    except Exception as e:
        if current_file:
            current_file.close()
        raise Exception(f"åˆ†å‰²æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    return stats


def parse_arguments():
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°
    
    Returns:
        argparse.Namespace: è§£æåçš„å‚æ•°
    """
    parser = argparse.ArgumentParser(
        description="åˆ†å‰²JSONLæ–‡ä»¶ä¸ºå¤šä¸ªå°æ–‡ä»¶",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  %(prog)s data.jsonl                     # é»˜è®¤æ¯10ä¸‡è¡Œåˆ†å‰²
  %(prog)s data.jsonl -n 50000            # æ¯5ä¸‡è¡Œåˆ†å‰²
  %(prog)s data.jsonl -o ./split_files    # æŒ‡å®šè¾“å‡ºç›®å½•
  %(prog)s data.jsonl --validate          # éªŒè¯JSONæ ¼å¼
  %(prog)s data.jsonl -n 200000 --validate -o output  # ç»„åˆå‚æ•°
        """
    )
    
    parser.add_argument(
        'input_file',
        help='è¦åˆ†å‰²çš„JSONLæ–‡ä»¶è·¯å¾„'
    )
    
    parser.add_argument(
        '-n', '--lines',
        type=int,
        default=100000,
        help='æ¯ä¸ªè¾“å‡ºæ–‡ä»¶çš„è¡Œæ•°ï¼ˆé»˜è®¤: 100000ï¼‰'
    )
    
    parser.add_argument(
        '-o', '--output',
        type=str,
        help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: è¾“å…¥æ–‡ä»¶æ‰€åœ¨ç›®å½•/æ–‡ä»¶å_splitï¼‰'
    )
    
    parser.add_argument(
        '--validate',
        action='store_true',
        help='åˆ†å‰²æ—¶éªŒè¯JSONæ ¼å¼ï¼Œè·³è¿‡æ— æ•ˆè¡Œ'
    )
    
    return parser.parse_args()


def main():
    """
    ä¸»å‡½æ•°
    """
    print("ğŸš€ JSONLæ–‡ä»¶åˆ†å‰²å™¨å¯åŠ¨")
    print("=" * 60)
    
    try:
        args = parse_arguments()
        
        # ç¡®å®šè¾“å‡ºç›®å½•
        if args.output:
            output_dir = args.output
        else:
            input_path = Path(args.input_file)
            output_dir = input_path.parent / f"{input_path.stem}_split"
        
        # éªŒè¯å‚æ•°
        if args.lines <= 0:
            raise ValueError("æ¯æ–‡ä»¶è¡Œæ•°å¿…é¡»å¤§äº0")
        
        # æ‰§è¡Œåˆ†å‰²
        stats = split_jsonl_file(
            input_file=args.input_file,
            output_dir=output_dir,
            lines_per_file=args.lines,
            validate=args.validate
        )
        
        # è¾“å‡ºç»Ÿè®¡ç»“æœ
        print("=" * 60)
        print("ğŸ“Š åˆ†å‰²å®Œæˆç»Ÿè®¡:")
        print(f"   ğŸ“ æ€»å¤„ç†è¡Œæ•°: {stats['total_lines']:,}")
        print(f"   âœ… æœ‰æ•ˆè¡Œæ•°: {stats['valid_lines']:,}")
        
        if args.validate and stats['invalid_lines'] > 0:
            print(f"   âŒ æ— æ•ˆè¡Œæ•°: {stats['invalid_lines']:,}")
        
        if stats['empty_lines_skipped'] > 0:
            print(f"   â­ï¸  è·³è¿‡ç©ºè¡Œ: {stats['empty_lines_skipped']:,}")
        
        print(f"   ğŸ“¦ ç”Ÿæˆæ–‡ä»¶æ•°: {len(stats['output_files'])}")
        print(f"   ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        
        # æ˜¾ç¤ºç”Ÿæˆçš„æ–‡ä»¶åˆ—è¡¨
        if len(stats['output_files']) <= 10:
            print("\nğŸ“„ ç”Ÿæˆçš„æ–‡ä»¶:")
            for file_path in stats['output_files']:
                file_size = os.path.getsize(file_path) / (1024 * 1024)
                print(f"   {os.path.basename(file_path)} ({file_size:.2f} MB)")
        else:
            print(f"\nğŸ“„ ç”Ÿæˆäº† {len(stats['output_files'])} ä¸ªæ–‡ä»¶")
            print(f"   ç¬¬ä¸€ä¸ª: {os.path.basename(stats['output_files'][0])}")
            print(f"   æœ€åä¸€ä¸ª: {os.path.basename(stats['output_files'][-1])}")
        
        print("\nâœ¨ åˆ†å‰²å®Œæˆï¼")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
