#!/usr/bin/env python3
"""
äº¤äº’å¼èŠå¤©æ¨¡å¼ - ä¸è®­ç»ƒå¥½çš„LLMæ¨¡å‹å¯¹è¯
"""

from data_processor import DataProcessor, download_and_prepare_data
from config_manager import get_config_manager
from infer import sample_next_token, load_model_and_config, warmup_model
import torch
import json
import os
import sys
import time
from typing import List, Dict

class ChatBot:
    def __init__(self, model_dir="./model_save"):
        """åˆå§‹åŒ–èŠå¤©æœºå™¨äºº"""
        self.model_dir = model_dir
        self.model = None
        self.config = None
        self.itos = None
        self.stoi = None
        self.conversation_history = []
        
        # åŠ è½½æ¨¡å‹å’Œé…ç½®
        self._load_model(config_path="config/config.yaml")
        
    def _load_model(self, config_path):
        """åŠ è½½æ¨¡å‹å’Œç›¸å…³é…ç½®"""
        try:
            # è¯¢é—®æ˜¯å¦éœ€è¦é¢„çƒ­ï¼ˆåŠ é€Ÿé¦–æ¬¡æ¨ç†ï¼‰
            warmup_choice = input("ğŸ”¥ æ˜¯å¦é¢„çƒ­æ¨¡å‹ä»¥åŠ é€Ÿé¦–æ¬¡æ¨ç†ï¼Ÿ(y/n, é»˜è®¤y): ").strip().lower()
            enable_warmup = warmup_choice != 'n'
            
            # ä½¿ç”¨ç»Ÿä¸€çš„æ¨¡å‹åŠ è½½å‡½æ•°
            self.model, self.config = load_model_and_config(self.model_dir, enable_warmup=enable_warmup)

            # å‡†å¤‡è¯è¡¨
            print("ğŸ“š å‡†å¤‡è¯è¡¨...")
            # è¯»å–é…ç½®ä»¥ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„åˆ†è¯å™¨
            config_manager = get_config_manager(config_path)
            data_config = config_manager.get_data_config()
            use_bpe = data_config.get('use_bpe_tokenizer', False)  # é»˜è®¤falseç¡®ä¿å…¼å®¹æ€§
            print(f"ğŸ”¤ ä½¿ç”¨åˆ†è¯å™¨ç±»å‹: {'BPE' if use_bpe else 'å­—ç¬¦çº§'}")
            
            # åˆ›å»ºæ•°æ®å¤„ç†å™¨
            tokenizer_type = "chinese_bpe" if use_bpe else "char_level"
            vocab_path = data_config.get('vocab_cache_path', 'chinese_tokenizer_vocab.json') if use_bpe else None
            self.data_processor = DataProcessor(tokenizer_type=tokenizer_type, vocab_path=vocab_path)
            
            dataset, vocab, itos, stoi = self.data_processor.download_and_prepare_data()
            self.itos = itos
            self.stoi = stoi
            print("âœ… è¯è¡¨å‡†å¤‡å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            sys.exit(1)

    def _encode_text(self, text: str) -> List[int]:
        """å°†æ–‡æœ¬ç¼–ç ä¸ºtokenåºåˆ—"""
        # ä½¿ç”¨data_processorè¿›è¡Œç¼–ç ï¼ˆæ”¯æŒBPEï¼‰
        if hasattr(self, 'data_processor') and self.data_processor:
            return self.data_processor.encode_text(text)
        else:
            # é™çº§åˆ°å­—ç¬¦çº§ç¼–ç 
            return [self.stoi.get(ch, 0) for ch in text if ch in self.stoi]

    def _decode_tokens(self, tokens: List[int]) -> str:
        """å°†tokenåºåˆ—è§£ç ä¸ºæ–‡æœ¬"""
        # ä½¿ç”¨data_processorè¿›è¡Œè§£ç ï¼ˆæ”¯æŒBPEï¼‰
        if hasattr(self, 'data_processor') and self.data_processor:
            return self.data_processor.decode_text(tokens)
        else:
            # é™çº§åˆ°å­—ç¬¦çº§è§£ç 
            return ''.join([self.itos.get(idx, '') for idx in tokens])

    def generate_response(self, prompt: str, max_tokens: int = 150, 
                         temperature: float = 0.8, top_k: int = 50, top_p: float = 0.9) -> str:
        """ç”Ÿæˆå›å¤"""
        device = self.config['device']
        
        # ç¼–ç è¾“å…¥
        input_tokens = self._encode_text(prompt)
        if not input_tokens:
            return "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç†è§£æ‚¨çš„è¾“å…¥ã€‚"
            
        # è½¬æ¢ä¸ºå¼ é‡
        idx = torch.tensor([input_tokens], dtype=torch.long, device=device)
        # idx = torch.randint(1, 4000, (5, 1)).long().to(device)
        # ç”Ÿæˆå›å¤
        generated_tokens = []
        
        with torch.no_grad():
            for step in range(max_tokens):
                # è·å–å½“å‰ä¸Šä¸‹æ–‡
                context = idx[:, -self.config['context_window']:]
                
                # å‰å‘ä¼ æ’­
                logits = self.model(context)
                last_logits = logits[:, -1, :]
                
                # é‡‡æ ·ä¸‹ä¸€ä¸ªtoken
                next_token = sample_next_token(
                    last_logits, 
                    temperature=temperature, 
                    top_k=top_k, 
                    top_p=top_p
                )
                
                # æ·»åŠ åˆ°åºåˆ—
                idx = torch.cat([idx, next_token], dim=-1)
                generated_tokens.append(next_token[0].item())
                
                # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†ç»“æŸç¬¦æˆ–æ ‡ç‚¹
                try:
                    new_char = self._decode_tokens([next_token[0].item()])
                except:
                    new_char = ''

                # å¦‚æœç”Ÿæˆäº†æ¢è¡Œç¬¦ä¸”é•¿åº¦è¶³å¤Ÿï¼Œä¹Ÿå¯ä»¥åœæ­¢
                if new_char == '\n' and len(generated_tokens) >= max_tokens - 10:
                    break
        
        # è§£ç ç”Ÿæˆçš„æ–‡æœ¬
        response = self._decode_tokens(generated_tokens).strip()
        return response

    def _fake_stream_output(self, text: str, delay: float = 0.03):
        """å‡çš„æµå¼è¾“å‡ºæ•ˆæœ - é€å­—ç¬¦æ˜¾ç¤ºå·²ç”Ÿæˆçš„å®Œæ•´æ–‡æœ¬"""
        print("ğŸ¤– åŠ©æ‰‹: ", end="", flush=True)
        
        for char in text:
            print(char, end="", flush=True)
            time.sleep(delay)  # æ§åˆ¶æ˜¾ç¤ºé€Ÿåº¦
        
        print()  # æ¢è¡Œ

    def add_to_history(self, user_input: str, bot_response: str):
        """æ·»åŠ å¯¹è¯åˆ°å†å²è®°å½•"""
        self.conversation_history.append({
            'user': user_input,
            'bot': bot_response
        })
        
        # ä¿æŒå†å²è®°å½•ä¸è¶…è¿‡10è½®å¯¹è¯
        if len(self.conversation_history) > 10:
            self.conversation_history.pop(0)

    def get_context_prompt(self, current_input: str) -> str:
        """æ„å»ºåŒ…å«å†å²å¯¹è¯çš„æç¤º"""
        context_parts = []
        
        # æ·»åŠ æœ€è¿‘å‡ è½®å¯¹è¯ä½œä¸ºä¸Šä¸‹æ–‡
        for item in self.conversation_history[-3:]:  # æœ€å¤š3è½®å†å²
            context_parts.append(f"ç”¨æˆ·ï¼š{item['user']}")
            context_parts.append(f"åŠ©æ‰‹ï¼š{item['bot']}")
        
        # æ·»åŠ å½“å‰è¾“å…¥
        context_parts.append(f"ç”¨æˆ·ï¼š{current_input}")
        context_parts.append("åŠ©æ‰‹ï¼š")
        
        return ''.join(context_parts)

    def chat(self):
        """å¼€å§‹èŠå¤©å¾ªç¯"""
        print("\n" + "="*60)
        print("ğŸ¤– è¥¿æ¸¸è®°AIåŠ©æ‰‹å·²å¯åŠ¨ï¼")
        print("ğŸ’¡ æ‚¨å¯ä»¥å’Œæˆ‘èŠå¤©ï¼Œæˆ‘ä¼šç”¨è¥¿æ¸¸è®°çš„é£æ ¼å›å¤æ‚¨")
        print("ğŸ“ è¾“å…¥ 'quit'ã€'exit' æˆ– 'bye' é€€å‡º")
        print("ğŸ›ï¸ è¾“å…¥ 'settings' æŸ¥çœ‹å’Œä¿®æ”¹ç”Ÿæˆå‚æ•°")
        print("ğŸ“œ è¾“å…¥ 'history' æŸ¥çœ‹å¯¹è¯å†å²")
        print("ğŸ”„ è¾“å…¥ 'clear' æ¸…ç©ºå¯¹è¯å†å²")
        print("âš¡ è¾“å…¥ 'stream' åˆ‡æ¢æµå¼è¾“å‡ºæ˜¾ç¤ºæ¨¡å¼")
        print("="*60)
        
        # é»˜è®¤ç”Ÿæˆå‚æ•° - å¢åŠ è¾“å‡ºé•¿åº¦
        settings = {
            'max_tokens': 150,
            'temperature': 0.8,
            'top_k': 50,
            'top_p': 0.9,
            'stream_delay': 0.03  # æµå¼è¾“å‡ºå»¶è¿Ÿï¼ˆç§’ï¼‰
        }
        
        # å®æ—¶ç”Ÿæˆæ˜¾ç¤ºæ¨¡å¼
        stream_mode = True  # é»˜è®¤å¼€å¯å®æ—¶æ˜¾ç¤º
        
        while True:
            try:
                user_input = input("\nğŸ‘¤ æ‚¨: ").strip()
                
                if not user_input:
                    continue
                    
                # å¤„ç†ç‰¹æ®Šå‘½ä»¤
                if user_input.lower() in ['quit', 'exit', 'bye']:
                    print("ğŸ‘‹ å†è§ï¼æ„Ÿè°¢ä½¿ç”¨è¥¿æ¸¸è®°AIåŠ©æ‰‹ï¼")
                    break
                    
                elif user_input.lower() == 'settings':
                    self._show_settings(settings)
                    continue
                    
                elif user_input.lower() == 'history':
                    self._show_history()
                    continue
                    
                elif user_input.lower() == 'clear':
                    self.conversation_history.clear()
                    print("ğŸ—‘ï¸ å¯¹è¯å†å²å·²æ¸…ç©º")
                    continue
                    
                elif user_input.lower() == 'stream':
                    stream_mode = not stream_mode
                    status = "å¼€å¯" if stream_mode else "å…³é—­"
                    print(f"âš¡ æµå¼è¾“å‡ºæ˜¾ç¤ºå·²{status}")
                    continue
                
                # æ„å»ºä¸Šä¸‹æ–‡æç¤º
                context_prompt = self.get_context_prompt(user_input)
                
                # ç”Ÿæˆå›å¤ - æ˜¾ç¤ºæ€è€ƒä¸­æç¤º
                thinking_text = "ğŸ¤” æ€è€ƒä¸­..."
                print(thinking_text, end="", flush=True)
                
                response = self.generate_response(
                    context_prompt,
                    max_tokens=settings['max_tokens'],
                    temperature=settings['temperature'],
                    top_k=settings['top_k'],
                    top_p=settings['top_p']
                )
                
                # æ¸…é™¤"æ€è€ƒä¸­..."æç¤º - ä½¿ç”¨è¶³å¤Ÿé•¿çš„ç©ºæ ¼æ¥è¦†ç›–
                clear_spaces = " " * (len(thinking_text) + 5)  # é¢å¤–å¢åŠ 5ä¸ªç©ºæ ¼ç¡®ä¿å®Œå…¨è¦†ç›–
                print(f"\r{clear_spaces}\r", end="", flush=True)

                # å¦‚æœä¸æ˜¯æµå¼æ¨¡å¼ï¼Œç›´æ¥æ˜¾ç¤ºå®Œæ•´å›å¤
                if not stream_mode:
                    print(f"ğŸ¤– åŠ©æ‰‹: {response}")
                else:
                    # å¦‚æœéœ€è¦æ˜¾ç¤ºè¿›åº¦ï¼Œä½¿ç”¨å‡æµå¼è¾“å‡º
                    self._fake_stream_output(response, delay=settings['stream_delay'])
                
                if response:
                    self.add_to_history(user_input, response)
                else:
                    print("ğŸ¤– åŠ©æ‰‹: æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚")
                    
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ å†è§ï¼æ„Ÿè°¢ä½¿ç”¨è¥¿æ¸¸è®°AIåŠ©æ‰‹ï¼")
                break
            except Exception as e:
                print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
                print("ğŸ”„ è¯·é‡è¯•...")

    def _show_settings(self, settings: Dict):
        """æ˜¾ç¤ºå’Œä¿®æ”¹è®¾ç½®"""
        print("\nâš™ï¸ å½“å‰ç”Ÿæˆå‚æ•°:")
        for key, value in settings.items():
            print(f"  {key}: {value}")
        
        print("\nğŸ’¡ å‚æ•°è¯´æ˜:")
        print("  max_tokens: æœ€å¤§ç”Ÿæˆé•¿åº¦ (20-300)")
        print("  temperature: éšæœºæ€§ (0.1-2.0, è¶Šå°è¶Šä¿å®ˆ)")
        print("  top_k: å€™é€‰è¯æ•°é‡ (1-100, 0è¡¨ç¤ºä¸é™åˆ¶)")
        print("  top_p: ç´¯ç§¯æ¦‚ç‡é˜ˆå€¼ (0.1-1.0)")
        print("  stream_delay: æµå¼è¾“å‡ºå»¶è¿Ÿç§’æ•° (0.01-0.1)")
        
        modify = input("\nğŸ”§ æ˜¯å¦è¦ä¿®æ”¹å‚æ•°ï¼Ÿ(y/n): ").strip().lower()
        if modify == 'y':
            try:
                for key in settings.keys():
                    new_value = input(f"  {key} (å½“å‰: {settings[key]}): ").strip()
                    if new_value:
                        if key == 'max_tokens':
                            settings[key] = max(20, min(300, int(new_value)))
                        elif key == 'temperature':
                            settings[key] = max(0.1, min(2.0, float(new_value)))
                        elif key == 'top_k':
                            settings[key] = max(0, min(100, int(new_value)))
                        elif key == 'top_p':
                            settings[key] = max(0.1, min(1.0, float(new_value)))
                        elif key == 'stream_delay':
                            settings[key] = max(0.01, min(0.1, float(new_value)))
                print("âœ… å‚æ•°å·²æ›´æ–°")
            except ValueError:
                print("âŒ å‚æ•°æ ¼å¼é”™è¯¯ï¼Œä¿æŒåŸè®¾ç½®")

    def _show_history(self):
        """æ˜¾ç¤ºå¯¹è¯å†å²"""
        if not self.conversation_history:
            print("ğŸ“ æš‚æ— å¯¹è¯å†å²")
            return
            
        print(f"\nğŸ“œ å¯¹è¯å†å² (æœ€è¿‘{len(self.conversation_history)}è½®):")
        print("-" * 50)
        for i, item in enumerate(self.conversation_history, 1):
            print(f"{i}. ğŸ‘¤ ç”¨æˆ·: {item['user']}")
            print(f"   ğŸ¤– åŠ©æ‰‹: {item['bot']}")
            print()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨è¥¿æ¸¸è®°AIèŠå¤©åŠ©æ‰‹...")
    
    try:
        chatbot = ChatBot()
        chatbot.chat()
    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")
        print("ğŸ’¡ è¯·ç¡®ä¿å·²ç»è®­ç»ƒäº†æ¨¡å‹å¹¶ä¿å­˜åœ¨ ./model_save/ ç›®å½•ä¸‹")

if __name__ == "__main__":
    main()
